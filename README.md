# Awesome Symbolic Regression

This repository is a collection of papers, methods, benchmarks and datasets of SR(Symbolic Regression).

## Papers

### Survey

La Cava, William, et al. **Contemporary symbolic regression methods and their relative performance**. *arXiv preprint arXiv:2107.14351* (2021).[paper](http://arxiv.org/abs/2107.14351)

### GP

H. Zhang, A. Zhou, Q. Chen, B. Xue and M. Zhang, **SR-Forest: A Genetic Programming based Heterogeneous Ensemble Learning Method**, in IEEE Transactions on Evolutionary Computation, doi: 10.1109/TEVC.2023.3243172.[paper](https://ieeexplore.ieee.org/document/10040601) [code](https://github.com/hengzhe-zhang/EvolutionaryForest)

William La Cava, Tilak Raj Singh, James Taggart, Srinivas Suri, and Jason H. Moore. **Learning concise representations for regression by evolving networks of trees. In International Conference on Learning Representations**, ICLR, 2019.[paper](https://arxiv.org/abs/1807.00981) [code](https://github.com/cavalab/feat)

Marco Virgolin, Tanja Alderliesten, Cees Witteveen, and Peter A N Bosman. **Improving model-based genetic programming for symbolic regression of small expressions**. Evolutionary Computation, page tba, 2020.[paper](https://arxiv.org/abs/1904.02050) [code](https://github.com/marcovirgolin/GP-GOMEA/)

F. O. de Franca and G. S. I. Aldeia. **Interaction-Transformation Evolutionary Algorithm for Symbolic Regression**. Evolutionary Computation, pages 1â€“25, December 2020. ISSN 1063-6560. doi: 10.1162/ evco_a_00285.[paper](https://arxiv.org/abs/1902.03983) [code](https://arxiv.org/abs/1902.03983)

Michael Kommenda, Bogdan Burlacu, Gabriel Kronberger, and Michael Affenzeller. **Parameter identification for symbolic regression using nonlinear least squares**. Genetic Programming and Evolvable Machines, December 2019. ISSN 1573-7632. doi: 10.1007/s10710-019-09371-3.[paper](https://link.springer.com/article/10.1007/s10710-019-09371-3) [code](https://github.com/heal-research/operon)

### DSR

Tenachi, Wassim, Rodrigo Ibata, and Foivos I. Diakogiannis. **Deep symbolic regression for physics guided by units constraints: toward the automated discovery of physical laws**. *arXiv preprint arXiv:2303.03192* (2023).[paper](https://arxiv.org/abs/2303.03192) [code](https://github.com/wassimtenachi/physo)

Brenden K. Petersen, Mikel Landajuela Larma, Terrell N. Mundhenk, Claudio Prata Santiago, Soo Kyung Kim, and Joanne Taery Kim. **Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients**. In International Conference on Learning Representations, September 2020.[paper](https://arxiv.org/abs/1912.04871) [code](https://github.com/brendenpetersen/deep-symbolic-optimization)

> The repository of the paper above contains code supporting the publications below.

Petersen et al. 2021 **Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients.** *ICLR 2021.* [Oral](https://iclr.cc/virtual/2021/poster/2578) [Paper](https://openreview.net/forum?id=m5Qsh0kBQG)

Landajuela et al. 2021 **Discovering symbolic policies with deep reinforcement learning.** *ICML 2021.* [Paper](https://proceedings.mlr.press/v139/landajuela21a.html)

Mundhenk et al. 2021 **Symbolic Regression via Neural-Guided Genetic Programming Population Seeding.** *NeurIPS 2021* [Paper](https://proceedings.neurips.cc/paper/2021/hash/d073bb8d0c47f317dd39de9c9f004e9d-Abstract.html)

Landajuela et al. 2022 **A Unified Framework for Deep Symbolic Regression.** *NeurIPS 2022* [Paper](https://openreview.net/forum?id=2FNnBhwJsHK)

Landajuela et al. 2021 **Improving exploration in policy gradient search: Application to symbolic optimization.** *Math-AI @ ICLR 2021.* [Paper](https://mathai-iclr.github.io/papers/papers/MATHAI_16_paper.pdf)

Kim et al. 2020 **An interactive visualization platform for deep symbolic regression.** *IJCAI 2020.* [Paper](https://www.ijcai.org/Proceedings/2020/0763.pdf)

Petersen et al. 2021 **Incorporating domain knowledge into neural-guided search via \*in situ\* priors and constraints** *AutoML @ ICML 2021.* [Paper](https://github.com/brendenpetersen/deep-symbolic-optimization/blob/master)

Kim et al. 2021 **Distilling Wikipedia mathematical knowledge into neural network models.** *Math-AI @ ICLR 2021.* [Paper](https://mathai-iclr.github.io/papers/papers/MATHAI_15_paper.pdf)

Silva et al. 2022 **Leveraging Language Models to Efficiently Learn Symbolic Optimization Solutions** *ALA Workshop 2022.* [Paper](https://ala2022.github.io/papers/ALA2022_paper_24.pdf)

Glatt et al. 2022 **Deep Symbolic Optimization for Electric Component Sizing in Fixed Topology Power Converters** *AI for Design and Manufacturing (ADAM) @ AAAI 2022.* [Paper](https://openreview.net/forum?id=u_ghY9PnAyZ)

### Physics-inspired

Silviu-Marian Udrescu, Andrew Tan, Jiahai Feng, Orisvaldo Neto, Tailin Wu, and Max Tegmark. **AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity**. arXiv:2006.10782 [physics, stat], December 2020.[paper](https://arxiv.org/pdf/1905.11481v2.pdf) [code](https://github.com/SJ001/AI-Feynman)



## Benchmarks

- [srsd](https://github.com/omron-sinicx/srsd-benchmark)
- [srbench](https://github.com/cavalab/srbench)

## Tools

- [PySR](https://github.com/MilesCranmer/PySR)
- [gplearn](https://github.com/trevorstephens/gplearn)
- [dso](https://github.com/brendenpetersen/deep-symbolic-optimization)
- [torchdiffeq](https://github.com/rtqichen/torchdiffeq)

